{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e434d132-c2c7-452d-9d47-df6e95f9bb3e",
   "metadata": {},
   "source": [
    "# environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e4ad50-fe6d-47d0-9bf0-dd6373782173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('/app/')\n",
    "os.chdir('/app')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578862a-6355-4111-8444-498d8acab410",
   "metadata": {},
   "source": [
    "# Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa344e01-861c-43f5-abe6-4cd4a1032486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠋ openai/gpt-4o                         0% 0:00:01   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠹ openai/gpt-4o                         0% 0:00:02   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠴ openai/gpt-4o                         0% 0:00:03   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠧ openai/gpt-4o                         0% 0:00:04   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠋ openai/gpt-4o                         0% 0:00:05   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠹ openai/gpt-4o  ━━━━╸                 25% 0:00:06   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠴ openai/gpt-4o  ━━━━╸                 25% 0:00:07   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠧ openai/gpt-4o  ━━━━━━━               37% 0:00:08   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠋ openai/gpt-4o  ━━━━━━━━━╸            49% 0:00:09   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠹ openai/gpt-4o  ━━━━━━━━━╸            49% 0:00:10   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠴ openai/gpt-4o  ━━━━━━━━━╸            49% 0:00:11   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠇ openai/gpt-4o  ━━━━━━━━━╸            49% 0:00:12   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 4/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠋ openai/gpt-4o  ━━━━━━━━━━━━          61% 0:00:13   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 3/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠸ openai/gpt-4o  ━━━━━━━━━━━━          61% 0:00:14   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 3/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠴ openai/gpt-4o  ━━━━━━━━━━━━          61% 0:00:15   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 3/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠇ openai/gpt-4o  ━━━━━━━━━━━━━━╸       74% 0:00:16   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 2/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠋ openai/gpt-4o  ━━━━━━━━━━━━━━━━━     86% 0:00:17   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 1/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ ⠸ openai/gpt-4o  ━━━━━━━━━━━━━━━━━     86% 0:00:18   scorer: model_graded_qa │\n",
      "│                                                                              │\n",
      "│ \u001b[1mgpt-4o:\u001b[0m 1/10                                             HTTP rate limits: 0 │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ \u001b[1mtotal time:    \u001b[0m  0:00:19                             scorer: model_graded_qa │\n",
      "│ \u001b[1mopenai/gpt-4o  \u001b[0m  13,884 tokens [9,772 + 4,112]                               │\n",
      "│                                                                              │\n",
      "│ \u001b[1maccuracy: 100\u001b[0m  \u001b[1mbootstrap_std: 0\u001b[0m                                              │\n",
      "│                                                                              │\n",
      "│ \u001b[1mLog:\u001b[0m ./logs/2024-07-14T21-30-10+00-00_translate_FyENmaVpehfBN8ATZTG5CA.json  │\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K╭─ \u001b[1mtranslate (4 samples): openai/gpt-4o\u001b[0m ───────────────────────────────────────╮\n",
      "│                                                           dataset: translate │\n",
      "│ \u001b[1mtotal time:    \u001b[0m  0:00:19                             scorer: model_graded_qa │\n",
      "│ \u001b[1mopenai/gpt-4o  \u001b[0m  13,884 tokens [9,772 + 4,112]                               │\n",
      "│                                                                              │\n",
      "│ \u001b[1maccuracy: 100\u001b[0m  \u001b[1mbootstrap_std: 0\u001b[0m                                              │\n",
      "│                                                                              │\n",
      "│ \u001b[1mLog:\u001b[0m ./logs/2024-07-14T21-30-10+00-00_translate_FyENmaVpehfBN8ATZTG5CA.json  │\n",
      "╰──────────────────────────────────────────────────────────────────────────────╯\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!inspect eval tests/inspect_ai/translate/translate.py --model 'openai/gpt-4o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4f96a7-1fbb-418d-9a20-82a25e2c4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Any\n",
    "\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "\n",
    "from inspect_ai._eval.registry import task\n",
    "from inspect_ai._eval.task import Task\n",
    "from inspect_ai.dataset import json_dataset\n",
    "from inspect_ai.model import Model, get_model\n",
    "from inspect_ai.scorer import scorer, accuracy, bootstrap_std, Scorer, Target, Score\n",
    "from inspect_ai.scorer._model import DEFAULT_MODEL_GRADED_QA_TEMPLATE\n",
    "from inspect_ai.solver import TaskState, Solver, solver\n",
    "\n",
    "from src.agents import make_tool_agent_executor\n",
    "from src.common.tools import ask, extract_grade\n",
    "from src.inspect_langchain import langchain_solver\n",
    "from src.templates.instructions import (\n",
    "    creation_prompt, scorers_header_task, scorers_instruction_task\n",
    ")\n",
    "\n",
    "\n",
    "@scorer(metrics=[accuracy(), bootstrap_std()])\n",
    "def model_graded_qa(\n",
    "        template: str = DEFAULT_MODEL_GRADED_QA_TEMPLATE, *args, model: str | Model | None = None, **kwargs\n",
    ") -> Scorer:\n",
    "    # resolve model\n",
    "    grader_model = get_model(model)\n",
    "\n",
    "    async def score(state: TaskState, target: Target) -> Score:\n",
    "        # format the model grading template\n",
    "        header = await ask(\n",
    "            grader_model, creation_prompt,\n",
    "            {'description': state.input_text, 'task': scorers_header_task}\n",
    "        )\n",
    "\n",
    "        hints = await ask(\n",
    "            grader_model,\n",
    "            creation_prompt,\n",
    "            {'description': state.input_text, \"task\": scorers_instruction_task}\n",
    "        )\n",
    "\n",
    "        score_prompt = template.format(\n",
    "            header=header.message.content,\n",
    "            question=state.input_text,\n",
    "            answer=state.output.completion,\n",
    "            criterion=target.text,\n",
    "            instructions=hints.message.content,\n",
    "        )\n",
    "\n",
    "        # query the model for the score\n",
    "        result = await grader_model.generate(score_prompt)\n",
    "\n",
    "        return extract_grade(result, metadata={'score_prompt': score_prompt})\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "@solver\n",
    "def agent(\n",
    "        max_iterations: int | None = 15, max_execution_time: float | None = None\n",
    ") -> Solver:\n",
    "    # agent function\n",
    "    async def agent(llm: BaseChatModel, input: dict[str, Any]):\n",
    "\n",
    "        agent_executor = await make_tool_agent_executor(\n",
    "            llm, input, max_iterations=max_iterations, max_execution_time=max_execution_time\n",
    "        )\n",
    "        # execute the agent and return output\n",
    "        result = await agent_executor.ainvoke(input)\n",
    "        return result[\"output\"]\n",
    "\n",
    "    # return agent function as inspect solver\n",
    "    return langchain_solver(agent)\n",
    "\n",
    "\n",
    "@task\n",
    "def translate() -> Task:\n",
    "    return Task(\n",
    "        dataset=json_dataset(\"/app/tests/inspect_ai/translate/translate.jsonl\"),\n",
    "        plan=agent(),\n",
    "        scorer=model_graded_qa(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb685643-a615-4e77-b61b-d6a02ef6a4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6bb0822ae84c4c878219ddc112cd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from inspect_ai import eval as eval_ai\n",
    "\n",
    "\n",
    "log = eval_ai(translate, model=\"openai/gpt-4o\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
